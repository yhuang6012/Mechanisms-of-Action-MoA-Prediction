{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "oof1 = pd.read_csv('oof_model3.csv') \n",
    "valid_list = oof1.sig_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 CV log_loss ALL: 0.015935769311927916\n",
      "4 CV log_loss ALL: 0.01588402198773087\n",
      "5 CV log_loss ALL: 0.015770070722981783\n",
      "10 CV log_loss ALL: 0.016631585348881373\n",
      "11 CV log_loss ALL: 0.015724777619773082\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for ii in [3,4,5,10,11]:\n",
    "    oof1 = pd.read_csv(f'oof_model{ii}.csv') \n",
    "    oof1 = oof1[oof1.sig_id.isin(valid_list)]\n",
    "    train_targets_scored = pd.read_csv('./input/lish-moa/train_targets_scored.csv')\n",
    "    train_targets_scored = train_targets_scored[train_targets_scored.sig_id.isin(valid_list)]\n",
    "    train_targets_scored = train_targets_scored.sort_values(by='sig_id')\n",
    "    oof1 = oof1.sort_values(by='sig_id')\n",
    "    sub_target_cols = train_targets_scored.columns.tolist()\n",
    "    sub_target_cols.remove('sig_id')\n",
    "    y_true = train_targets_scored[sub_target_cols].values\n",
    "    y_pred = oof1[sub_target_cols].values\n",
    "    from sklearn.metrics import log_loss\n",
    "    score = 0\n",
    "    for i in range(len(sub_target_cols)):\n",
    "        score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "        score += score_ / len(sub_target_cols)\n",
    "    print(ii,\"CV log_loss ALL:\", score) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_oof(ii):\n",
    "    oof1 = pd.read_csv(f'oof_model{ii}.csv') \n",
    "    oof1 = oof1[oof1.sig_id.isin(valid_list)]\n",
    "    oof1 = oof1.sort_values(by='sig_id')\n",
    "    oof1 = oof1.set_index('sig_id')\n",
    "    return oof1\n",
    "\n",
    "oof2 = get_oof(2)\n",
    "oof3 = get_oof(3)\n",
    "oof5 = get_oof(5)\n",
    "oof10 = get_oof(10)\n",
    "oof11 = get_oof(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_sub(ii):\n",
    "    oof1 = pd.read_csv(f'submission_model{ii}.csv') \n",
    "    oof1 = oof1.sort_values(by='sig_id')\n",
    "    oof1 = oof1.set_index('sig_id')\n",
    "    return oof1\n",
    "\n",
    "sub2 = get_sub(2)\n",
    "sub3 = get_sub(3)\n",
    "sub5 = get_sub(5)\n",
    "sub10 = get_sub(10)\n",
    "sub11 = get_sub(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from time import time\n",
    "# from autograd import grad\n",
    "# import autograd.numpy as np\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize, fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.read_csv('./input/lish-moa/train_targets_scored.csv')\n",
    "y_true = y_true[y_true.sig_id.isin(valid_list)]\n",
    "y_true = y_true.sort_values(by='sig_id')\n",
    "y_true = y_true.set_index('sig_id')\n",
    "y_true = y_true.values\n",
    "\n",
    "\n",
    "oof_dict = {\n",
    "            'Model 2': f'oof_model{2}.csv',\n",
    "            'Model 3': f'oof_model{3}.csv',\n",
    "            'Model 5': f'oof_model{5}.csv',            \n",
    "            'Model 10': f'oof_model{10}.csv',\n",
    "            'Model 11': f'oof_model{11}.csv'\n",
    "           }\n",
    "\n",
    "oof = np.zeros((len(oof_dict), y_true.shape[0], y_true.shape[1]))\n",
    "for ii in range(oof.shape[0]):\n",
    "    oof1 = pd.read_csv(list(oof_dict.values())[ii]) \n",
    "    oof1 = oof1[oof1.sig_id.isin(valid_list)].sort_values(by='sig_id')\n",
    "    oof1 = oof1.set_index('sig_id')\n",
    "    oof[ii] = oof1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 21948, 206)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPMP's logloss from https://www.kaggle.com/c/lish-moa/discussion/183010\n",
    "def log_loss_numpy(y_pred):\n",
    "    y_true_ravel = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = np.where(y_true_ravel == 1, - np.log(y_pred), - np.log(1 - y_pred))\n",
    "    return loss.mean()\n",
    "\n",
    "def func_numpy_metric(weights):\n",
    "    oof_blend = np.tensordot(weights, oof, axes = ((0), (0)))\n",
    "    return log_loss_numpy(oof_blend)\n",
    "\n",
    "def grad_func(weights):\n",
    "    oof_clip = np.clip(oof, 1e-15, 1 - 1e-15)\n",
    "    gradients = np.zeros(oof.shape[0])\n",
    "    for i in range(oof.shape[0]):\n",
    "        a, b, c = y_true, oof_clip[i], np.zeros((oof.shape[1], oof.shape[2]))\n",
    "        for j in range(oof.shape[0]):\n",
    "            if j != i:\n",
    "                c += weights[j] * oof_clip[j]\n",
    "        gradients[i] = -np.mean((-a*b+(b**2)*weights[i]+b*c)/((b**2)*(weights[i]**2)+2*b*c*weights[i]-b*weights[i]+(c**2)-c))\n",
    "    return gradients\n",
    "\n",
    "@njit\n",
    "def grad_func_jit(weights):\n",
    "    oof_clip = np.minimum(1 - 1e-15, np.maximum(oof, 1e-15))\n",
    "    gradients = np.zeros(oof.shape[0])\n",
    "    for i in range(oof.shape[0]):\n",
    "        a, b, c = y_true, oof_clip[i], np.zeros((oof.shape[1], oof.shape[2]))\n",
    "        for j in range(oof.shape[0]):\n",
    "            if j != i:\n",
    "                c += weights[j] * oof_clip[j]\n",
    "        gradients[i] = -np.mean((-a*b+(b**2)*weights[i]+b*c)/((b**2)*(weights[i]**2)+2*b*c*weights[i]-b*weights[i]+(c**2)-c))\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 CV:\t 0.01650430218101765\n",
      "Model 3 CV:\t 0.015935769311927916\n",
      "Model 5 CV:\t 0.015770070722981776\n",
      "Model 10 CV:\t 0.016631585348881373\n",
      "Model 11 CV:\t 0.01572477761977309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_loss_scores = {}\n",
    "for n, key in enumerate(oof_dict.keys()):\n",
    "    score_oof = log_loss_numpy(oof[n])\n",
    "    log_loss_scores[key] = score_oof\n",
    "    print(f'{key} CV:\\t', score_oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = np.array([1 / oof.shape[0]] * oof.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital Blend OOF: 0.01565017114194376\n",
      "Optimised Weights: [0.05347229 0.01524472 0.30185396 0.11718756 0.51224147]\n",
      "[00:38] Optimised Blend OOF: 0.015578943781218577\n"
     ]
    }
   ],
   "source": [
    "tol = 1e-10\n",
    "init_guess = [1 / oof.shape[0]] * oof.shape[0]\n",
    "bnds = [(0, 1) for _ in range(oof.shape[0])]\n",
    "cons = {'type': 'eq', \n",
    "        'fun': lambda x: np.sum(x) - 1, \n",
    "        'jac': lambda x: [1] * len(x)}\n",
    "\n",
    "print('Inital Blend OOF:', func_numpy_metric(init_guess))\n",
    "start_time = time()\n",
    "\n",
    "res_scipy = minimize(fun = func_numpy_metric, \n",
    "                     x0 = init_guess, \n",
    "                     method = 'SLSQP', \n",
    "                     jac = grad_func_jit, # grad_func \n",
    "                     bounds = bnds, \n",
    "                     constraints = cons, \n",
    "                     tol = tol)\n",
    "print('Optimised Weights:', res_scipy.x)\n",
    "\n",
    "print(f'[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] Optimised Blend OOF:', res_scipy.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the sum of all weights: 0.9999999999999999\n",
      "Great! The sum of all weights equals to 1!\n"
     ]
    }
   ],
   "source": [
    "print('Check the sum of all weights:', np.sum(res_scipy.x))\n",
    "if np.sum(res_scipy.x) - 1 <= tol:\n",
    "    print('Great! The sum of all weights equals to 1!')\n",
    "else:\n",
    "    print('Manual adjustion is needed to modify the weights.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = res_scipy.x\n",
    "\n",
    "sub = sub2*beta[0]+sub3*beta[1]+sub5*beta[2]+sub10*beta[3]+sub11*beta[4]\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
